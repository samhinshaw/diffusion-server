services:
  rabbitmq:
    image: rabbitmq:3.10-management-alpine
    container_name: diffusion_rabbitmq
    hostname: diffusion_rabbitmq
    expose:
      - 5672
    ports:
      - 15672:15672
    # volumes:
    #   - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
  server:
    build:
      context: .
      dockerfile: Dockerfile
    image: diffusion_server
    # command: ['python', 'app.py'] # dev mode
    command: ['flask', 'run', '--host=0.0.0.0', '--port=9022', '--with-threads']
    # command: ['tail', '-f', '/dev/null'] # debug command to keep container alive
    container_name: diffusion_server
    ports:
      - 9022:9022
    volumes:
      - .:/app
    depends_on:
      - rabbitmq
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: diffusion_server
    # command: ['python', 'app.py']
    command: ['celery', '--app=tasks', 'worker', '--loglevel=info']
    # command: ['tail', '-f', '/dev/null'] # debug command to keep container alive
    container_name: diffusion_worker
    depends_on:
      - rabbitmq
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    image: diffusion_server
    command: ['celery', '--app=tasks', 'beat', '--loglevel=info']
    volumes:
      - .:/app
    environment:
      - FLASK_APP=app
  # worker:
  #   image: myapp
  #   command: celery -A myapp worker -l info
  #   depends_on:
  #     - rabbitmq
  # gpu:
  #   image: nvidia/cuda:11.7.1-base-ubuntu22.04
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
